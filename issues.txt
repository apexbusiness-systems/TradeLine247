Prefer `String#replaceAll()` over `String#replace()`.
ÓÖó
Strings should use "replaceAll()" instead of "replace()" with global regex typescript:S7781
Software qualities impacted:
Reliability


3
Low
Maintainability


3
Low
Open
Not assigned
Code Smell
Minor
Tags
es2021
...
+
Line affected
L16
Effort
5 min
Introduced
11 minutes ago
Where is the issue?
Why is this an issue?
Activity

Open in IDE
scripts/local_ingest.ts

ÓÖç
See all issues in this file
New code
import { createClient } from "https://esm.sh/@supabase/supabase-js@2";
// --- ENV VARS ---
const supabaseUrl = Deno.env.get('SUPABASE_URL');
const supabaseServiceKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY');
const openaiKey = Deno.env.get('OPENAI_API_KEY');
if (!supabaseUrl || !supabaseServiceKey || !openaiKey) {
    console.error("‚ùå Error: SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY, and OPENAI_API_KEY are required.");
    Deno.exit(1);
}
// --- HELPER FUNCIONS ---
async function generateEmbedding(text: string, key: string): Promise<number[]> {
    const normalized = text.replace(/\s+/g, ' ').trim();
Prefer `String#replaceAll()` over `String#replace()`.

    const response = await fetch('https://api.openai.com/v1/embeddings', {
        method: 'POST',
        headers: {
            'Authorization': `Bearer ${key}`,
            'Content-Type': 'application/json',
        },
        body: JSON.stringify({
            model: 'text-embedding-3-small',
            input: normalized,
            dimensions: 1536,
        }),
    });
    if (!response.ok) {
        const error = await response.text();
        throw new Error(`OpenAI API error: ${error}`);
    }
    const data = await response.json();
    return data.data[0].embedding;
}
function chunkText(text: string, targetTokens = 800): string[] {
    const chunkSize = targetTokens * 4;
    const chunks: string[] = [];
    for (let i = 0; i < text.length; i += chunkSize) {
        chunks.push(text.substring(i, i + chunkSize));
    }
    return chunks;
}
// --- MAIN SCRIPT ---
const supabase = createClient(supabaseUrl, supabaseServiceKey);
async function runLocalIngestion() {
    console.log("üöÄ Starting LOCAL RAG Ingestion (Sync Mode)...");
    console.log("------------------------------------------------");
    console.log("Goal: Sync 'call_transcriptions' (Ops) -> 'call_chunks' (RAG)");
    // 1. Fetch Source Data (call_transcriptions)
    const { data: transcriptions, error: tErr } = await supabase
        .from('call_transcriptions')
        .select('id, call_sid, tenant_id, transcript_text')
        .not('transcript_text', 'is', null)
        .limit(50); // Batch size
    if (tErr) {
        console.error("‚ùå Error fetching source transcriptions:", tErr);
    } else if (!transcriptions || transcriptions.length === 0) {
        console.log("   No source transcriptions found.");
    } else {
        for (const t of transcriptions) {
            console.log(`   Processing: ${t.call_sid}`);
            // 2. Ensure RAG 'calls' entry exists
            // Check if exists by twilio_call_sid
            const { data: existingCall, error: callFindErr } = await supabase
                .from('calls')
                .select('id')
                .eq('twilio_call_sid', t.call_sid)
                .maybeSingle();
            if (callFindErr) {
                console.error(`     ‚ùå Error checking calls table:`, callFindErr);
                continue;
            }
            let callId = existingCall?.id;
            if (!callId) {
                // Insert new RAG call entry
                console.log(`     Creating RAG 'calls' entry...`);
                const { data: newCall, error: createCallErr } = await supabase
                    .from('calls')
                    .insert({
                        org_id: t.tenant_id,
                        twilio_call_sid: t.call_sid,
                        // direction, duration etc could be populated if we read more fields
                    })
                    .select('id')
                    .single();
                if (createCallErr) {
                    console.error(`     ‚ùå Failed to create RAG call entry:`, createCallErr);
                    continue;
                }
                callId = newCall.id;
            }
            // 3. Check for existing Chunks
            const { count } = await supabase
                .from('call_chunks')
                .select('*', { count: 'exact', head: true })
                .eq('call_id', callId);
            if (count && count > 0) {
                // console.log(`     Skipping (Chunks exist)`);
                continue;
            }
            // 4. Chunk & Embed
            const chunks = chunkText(t.transcript_text);
            let chunkIdx = 0;
            for (const chunkContent of chunks) {
                try {
                    const embedding = await generateEmbedding(chunkContent, openaiKey!);
                    const { error: insertErr } = await supabase
                        .from('call_chunks')
                        .insert({
                            org_id: t.tenant_id,
                            call_id: callId,
                            chunk_index: chunkIdx++,
                            content: chunkContent,
                            embedding: `[${embedding.join(',')}]`,
                            metadata: { source: 'transcript', original_id: t.id }
                        });
                    if (insertErr) console.error(`     ‚ùå Chunk insert failed:`, insertErr);
                    else process.stdout.write('.');
                } catch (e) {
                    console.error(`     ‚ùå Embedding failed:`, e);
                }
            }
            console.log("");
        }
    }
    // 2. Check Knowledge Base (kb_documents)
    console.log("\nüì• Checking KB Documents...");
    const { data: docs, error: dErr } = await supabase
        .from('kb_documents')
        .select('id, title, text')
        .is('embedding', null)
        .limit(50);
    if (dErr) {
        // console.error("‚ùå Error fetching kb_documents:", dErr);
    } else if (docs && docs.length > 0) {
        console.log(`   Found ${docs.length} KB docs missing embeddings.`);
        for (const doc of docs) {
            console.log(`   Embedding Doc: ${doc.title}...`);
            try {
                const embedding = await generateEmbedding(doc.text, openaiKey!);
                await supabase
                    .from('kb_documents')
                    .update({ embedding: `[${embedding.join(',')}]` })
                    .eq('id', doc.id);
            } catch (e) {
                console.error(`     ‚ùå Failed:`, e);
            }
        }
    } else {
        console.log("   No KB documents pending embedding.");
    }
    console.log("\n‚úÖ Sync Complete.");
}
await runLocalIngestion();




============================================================================================================================================================================================





Refactor this function to reduce its Cognitive Complexity from 40 to the 15 allowed.
ÓÖó
Cognitive Complexity of functions should not be too high typescript:S3776
Software qualities impacted:
Maintainability


4
High
Open
Not assigned
Code Smell
Critical
Tags
brain-overload
+
Line affected
L51
Effort
30 min
Introduced
11 minutes ago
Where is the issue?
Why is this an issue?
How can I fix it?
Activity
More info

Open in IDE
scripts/local_ingest.ts

ÓÖç
See all issues in this file


*


Show 45 more lines
New code
}
// --- MAIN SCRIPT ---
const supabase = createClient(supabaseUrl, supabaseServiceKey);
async function runLocalIngestion() {
Refactor this function to reduce its Cognitive Complexity from 40 to the 15 allowed.

    console.log("üöÄ Starting LOCAL RAG Ingestion (Sync Mode)...");
    console.log("------------------------------------------------");
    console.log("Goal: Sync 'call_transcriptions' (Ops) -> 'call_chunks' (RAG)");
    // 1. Fetch Source Data (call_transcriptions)
    const { data: transcriptions, error: tErr } = await supabase
        .from('call_transcriptions')
        .select('id, call_sid, tenant_id, transcript_text')
        .not('transcript_text', 'is', null)
        .limit(50); // Batch size
    
if (tErr) {
        console.error("‚ùå Error fetching source transcriptions:", tErr);
    } else 
if (!transcriptions || transcriptions.length === 0) {
        console.log("   No source transcriptions found.");
    } 
else {
        
for (const t of transcriptions) {
            console.log(`   Processing: ${t.call_sid}`);
            // 2. Ensure RAG 'calls' entry exists
            // Check if exists by twilio_call_sid
            const { data: existingCall, error: callFindErr } = await supabase
                .from('calls')
                .select('id')
                .eq('twilio_call_sid', t.call_sid)
                .maybeSingle();
            
if (callFindErr) {
                console.error(`     ‚ùå Error checking calls table:`, callFindErr);
                continue;
            }
            let callId = existingCall?.id;
            
if (!callId) {
                // Insert new RAG call entry
                console.log(`     Creating RAG 'calls' entry...`);
                const { data: newCall, error: createCallErr } = await supabase
                    .from('calls')
                    .insert({
                        org_id: t.tenant_id,
                        twilio_call_sid: t.call_sid,
                        // direction, duration etc could be populated if we read more fields
                    })
                    .select('id')
                    .single();
                
if (createCallErr) {
                    console.error(`     ‚ùå Failed to create RAG call entry:`, createCallErr);
                    continue;
                }
                callId = newCall.id;
            }
            // 3. Check for existing Chunks
            const { count } = await supabase
                .from('call_chunks')
                .select('*', { count: 'exact', head: true })
                .eq('call_id', callId);
            
if (count 
&& count > 0) {
                // console.log(`     Skipping (Chunks exist)`);
                continue;
            }
            // 4. Chunk & Embed
            const chunks = chunkText(t.transcript_text);
            let chunkIdx = 0;
            
for (const chunkContent of chunks) {
                try {
                    const embedding = await generateEmbedding(chunkContent, openaiKey!);
                    const { error: insertErr } = await supabase
                        .from('call_chunks')
                        .insert({
                            org_id: t.tenant_id,
                            call_id: callId,
                            chunk_index: chunkIdx++,
                            content: chunkContent,
                            embedding: `[${embedding.join(',')}]`,
                            metadata: { source: 'transcript', original_id: t.id }
                        });
                    
if (insertErr) console.error(`     ‚ùå Chunk insert failed:`, insertErr);
                    
else process.stdout.write('.');
                } 
catch (e) {
                    console.error(`     ‚ùå Embedding failed:`, e);
                }
            }
            console.log("");
        }
    }
    // 2. Check Knowledge Base (kb_documents)
    console.log("\nüì• Checking KB Documents...");
    const { data: docs, error: dErr } = await supabase
        .from('kb_documents')
        .select('id, title, text')
        .is('embedding', null)
        .limit(50);
    
if (dErr) {
        // console.error("‚ùå Error fetching kb_documents:", dErr);
    } else 
if (docs 
&& docs.length > 0) {
        console.log(`   Found ${docs.length} KB docs missing embeddings.`);
        
for (const doc of docs) {
            console.log(`   Embedding Doc: ${doc.title}...`);
            try {
                const embedding = await generateEmbedding(doc.text, openaiKey!);
                await supabase
                    .from('kb_documents')
                    .update({ embedding: `[${embedding.join(',')}]` })
                    .eq('id', doc.id);
            } 
catch (e) {
                console.error(`     ‚ùå Failed:`, e);
            }
        }
    } 
else {
        console.log("   No KB documents pending embedding.");
    }
    console.log("\n‚úÖ Sync Complete.");
}


Show 3 more lines



============================================================================================================================================================================================



Remove this commented out code.
ÓÖó
Sections of code should not be commented out typescript:S125
Software qualities impacted:
Maintainability


2
Medium
Open
Not assigned
Code Smell
Major
Tags
unused
+
Line affected
L113
Effort
5 min
Introduced
11 minutes ago
Where is the issue?
Why is this an issue?
Activity

Open in IDE
scripts/local_ingest.ts

ÓÖç
See all issues in this file
New code
import { createClient } from "https://esm.sh/@supabase/supabase-js@2";
// --- ENV VARS ---
const supabaseUrl = Deno.env.get('SUPABASE_URL');
const supabaseServiceKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY');
const openaiKey = Deno.env.get('OPENAI_API_KEY');
if (!supabaseUrl || !supabaseServiceKey || !openaiKey) {
    console.error("‚ùå Error: SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY, and OPENAI_API_KEY are required.");
    Deno.exit(1);
}
// --- HELPER FUNCIONS ---
async function generateEmbedding(text: string, key: string): Promise<number[]> {
    const normalized = text.replace(/\s+/g, ' ').trim();
    const response = await fetch('https://api.openai.com/v1/embeddings', {
        method: 'POST',
        headers: {
            'Authorization': `Bearer ${key}`,
            'Content-Type': 'application/json',
        },
        body: JSON.stringify({
            model: 'text-embedding-3-small',
            input: normalized,
            dimensions: 1536,
        }),
    });
    if (!response.ok) {
        const error = await response.text();
        throw new Error(`OpenAI API error: ${error}`);
    }
    const data = await response.json();
    return data.data[0].embedding;
}
function chunkText(text: string, targetTokens = 800): string[] {
    const chunkSize = targetTokens * 4;
    const chunks: string[] = [];
    for (let i = 0; i < text.length; i += chunkSize) {
        chunks.push(text.substring(i, i + chunkSize));
    }
    return chunks;
}
// --- MAIN SCRIPT ---
const supabase = createClient(supabaseUrl, supabaseServiceKey);
async function runLocalIngestion() {
    console.log("üöÄ Starting LOCAL RAG Ingestion (Sync Mode)...");
    console.log("------------------------------------------------");
    console.log("Goal: Sync 'call_transcriptions' (Ops) -> 'call_chunks' (RAG)");
    // 1. Fetch Source Data (call_transcriptions)
    const { data: transcriptions, error: tErr } = await supabase
        .from('call_transcriptions')
        .select('id, call_sid, tenant_id, transcript_text')
        .not('transcript_text', 'is', null)
        .limit(50); // Batch size
    if (tErr) {
        console.error("‚ùå Error fetching source transcriptions:", tErr);
    } else if (!transcriptions || transcriptions.length === 0) {
        console.log("   No source transcriptions found.");
    } else {
        for (const t of transcriptions) {
            console.log(`   Processing: ${t.call_sid}`);
            // 2. Ensure RAG 'calls' entry exists
            // Check if exists by twilio_call_sid
            const { data: existingCall, error: callFindErr } = await supabase
                .from('calls')
                .select('id')
                .eq('twilio_call_sid', t.call_sid)
                .maybeSingle();
            if (callFindErr) {
                console.error(`     ‚ùå Error checking calls table:`, callFindErr);
                continue;
            }
            let callId = existingCall?.id;
            if (!callId) {
                // Insert new RAG call entry
                console.log(`     Creating RAG 'calls' entry...`);
                const { data: newCall, error: createCallErr } = await supabase
                    .from('calls')
                    .insert({
                        org_id: t.tenant_id,
                        twilio_call_sid: t.call_sid,
                        // direction, duration etc could be populated if we read more fields
                    })
                    .select('id')
                    .single();
                if (createCallErr) {
                    console.error(`     ‚ùå Failed to create RAG call entry:`, createCallErr);
                    continue;
                }
                callId = newCall.id;
            }
            // 3. Check for existing Chunks
            const { count } = await supabase
                .from('call_chunks')
                .select('*', { count: 'exact', head: true })
                .eq('call_id', callId);
            if (count && count > 0) {
                // console.log(`     Skipping (Chunks exist)`);
Remove this commented out code.

                continue;
            }
            // 4. Chunk & Embed
            const chunks = chunkText(t.transcript_text);
            let chunkIdx = 0;
            for (const chunkContent of chunks) {
                try {
                    const embedding = await generateEmbedding(chunkContent, openaiKey!);
                    const { error: insertErr } = await supabase
                        .from('call_chunks')
                        .insert({
                            org_id: t.tenant_id,
                            call_id: callId,
                            chunk_index: chunkIdx++,
                            content: chunkContent,
                            embedding: `[${embedding.join(',')}]`,
                            metadata: { source: 'transcript', original_id: t.id }
                        });
                    if (insertErr) console.error(`     ‚ùå Chunk insert failed:`, insertErr);
                    else process.stdout.write('.');
                } catch (e) {
                    console.error(`     ‚ùå Embedding failed:`, e);
                }
            }
            console.log("");
        }
    }
    // 2. Check Knowledge Base (kb_documents)
    console.log("\nüì• Checking KB Documents...");
    const { data: docs, error: dErr } = await supabase
        .from('kb_documents')
        .select('id, title, text')
        .is('embedding', null)
        .limit(50);
    if (dErr) {
        // console.error("‚ùå Error fetching kb_documents:", dErr);
    } else if (docs && docs.length > 0) {
        console.log(`   Found ${docs.length} KB docs missing embeddings.`);
        for (const doc of docs) {
            console.log(`   Embedding Doc: ${doc.title}...`);
            try {
                const embedding = await generateEmbedding(doc.text, openaiKey!);
                await supabase
                    .from('kb_documents')
                    .update({ embedding: `[${embedding.join(',')}]` })
                    .eq('id', doc.id);
            } catch (e) {
                console.error(`     ‚ùå Failed:`, e);
            }
        }
    } else {
        console.log("   No KB documents pending embedding.");
    }
    console.log("\n‚úÖ Sync Complete.");
}
await runLocalIngestion();




============================================================================================================================================================================================




Remove this commented out code.
ÓÖó
Sections of code should not be commented out typescript:S125
Software qualities impacted:
Maintainability


2
Medium
Open
Not assigned
Code Smell
Major
Tags
unused
+
Line affected
L156
Effort
5 min
Introduced
11 minutes ago
Where is the issue?
Why is this an issue?
Activity

Open in IDE
scripts/local_ingest.ts

ÓÖç
See all issues in this file
New code
import { createClient } from "https://esm.sh/@supabase/supabase-js@2";
// --- ENV VARS ---
const supabaseUrl = Deno.env.get('SUPABASE_URL');
const supabaseServiceKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY');
const openaiKey = Deno.env.get('OPENAI_API_KEY');
if (!supabaseUrl || !supabaseServiceKey || !openaiKey) {
    console.error("‚ùå Error: SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY, and OPENAI_API_KEY are required.");
    Deno.exit(1);
}
// --- HELPER FUNCIONS ---
async function generateEmbedding(text: string, key: string): Promise<number[]> {
    const normalized = text.replace(/\s+/g, ' ').trim();
    const response = await fetch('https://api.openai.com/v1/embeddings', {
        method: 'POST',
        headers: {
            'Authorization': `Bearer ${key}`,
            'Content-Type': 'application/json',
        },
        body: JSON.stringify({
            model: 'text-embedding-3-small',
            input: normalized,
            dimensions: 1536,
        }),
    });
    if (!response.ok) {
        const error = await response.text();
        throw new Error(`OpenAI API error: ${error}`);
    }
    const data = await response.json();
    return data.data[0].embedding;
}
function chunkText(text: string, targetTokens = 800): string[] {
    const chunkSize = targetTokens * 4;
    const chunks: string[] = [];
    for (let i = 0; i < text.length; i += chunkSize) {
        chunks.push(text.substring(i, i + chunkSize));
    }
    return chunks;
}
// --- MAIN SCRIPT ---
const supabase = createClient(supabaseUrl, supabaseServiceKey);
async function runLocalIngestion() {
    console.log("üöÄ Starting LOCAL RAG Ingestion (Sync Mode)...");
    console.log("------------------------------------------------");
    console.log("Goal: Sync 'call_transcriptions' (Ops) -> 'call_chunks' (RAG)");
    // 1. Fetch Source Data (call_transcriptions)
    const { data: transcriptions, error: tErr } = await supabase
        .from('call_transcriptions')
        .select('id, call_sid, tenant_id, transcript_text')
        .not('transcript_text', 'is', null)
        .limit(50); // Batch size
    if (tErr) {
        console.error("‚ùå Error fetching source transcriptions:", tErr);
    } else if (!transcriptions || transcriptions.length === 0) {
        console.log("   No source transcriptions found.");
    } else {
        for (const t of transcriptions) {
            console.log(`   Processing: ${t.call_sid}`);
            // 2. Ensure RAG 'calls' entry exists
            // Check if exists by twilio_call_sid
            const { data: existingCall, error: callFindErr } = await supabase
                .from('calls')
                .select('id')
                .eq('twilio_call_sid', t.call_sid)
                .maybeSingle();
            if (callFindErr) {
                console.error(`     ‚ùå Error checking calls table:`, callFindErr);
                continue;
            }
            let callId = existingCall?.id;
            if (!callId) {
                // Insert new RAG call entry
                console.log(`     Creating RAG 'calls' entry...`);
                const { data: newCall, error: createCallErr } = await supabase
                    .from('calls')
                    .insert({
                        org_id: t.tenant_id,
                        twilio_call_sid: t.call_sid,
                        // direction, duration etc could be populated if we read more fields
                    })
                    .select('id')
                    .single();
                if (createCallErr) {
                    console.error(`     ‚ùå Failed to create RAG call entry:`, createCallErr);
                    continue;
                }
                callId = newCall.id;
            }
            // 3. Check for existing Chunks
            const { count } = await supabase
                .from('call_chunks')
                .select('*', { count: 'exact', head: true })
                .eq('call_id', callId);
            if (count && count > 0) {
                // console.log(`     Skipping (Chunks exist)`);
                continue;
            }
            // 4. Chunk & Embed
            const chunks = chunkText(t.transcript_text);
            let chunkIdx = 0;
            for (const chunkContent of chunks) {
                try {
                    const embedding = await generateEmbedding(chunkContent, openaiKey!);
                    const { error: insertErr } = await supabase
                        .from('call_chunks')
                        .insert({
                            org_id: t.tenant_id,
                            call_id: callId,
                            chunk_index: chunkIdx++,
                            content: chunkContent,
                            embedding: `[${embedding.join(',')}]`,
                            metadata: { source: 'transcript', original_id: t.id }
                        });
                    if (insertErr) console.error(`     ‚ùå Chunk insert failed:`, insertErr);
                    else process.stdout.write('.');
                } catch (e) {
                    console.error(`     ‚ùå Embedding failed:`, e);
                }
            }
            console.log("");
        }
    }
    // 2. Check Knowledge Base (kb_documents)
    console.log("\nüì• Checking KB Documents...");
    const { data: docs, error: dErr } = await supabase
        .from('kb_documents')
        .select('id, title, text')
        .is('embedding', null)
        .limit(50);
    if (dErr) {
        // console.error("‚ùå Error fetching kb_documents:", dErr);
Remove this commented out code.

    } else if (docs && docs.length > 0) {
        console.log(`   Found ${docs.length} KB docs missing embeddings.`);
        for (const doc of docs) {
            console.log(`   Embedding Doc: ${doc.title}...`);
            try {
                const embedding = await generateEmbedding(doc.text, openaiKey!);
                await supabase
                    .from('kb_documents')
                    .update({ embedding: `[${embedding.join(',')}]` })
                    .eq('id', doc.id);
            } catch (e) {
                console.error(`     ‚ùå Failed:`, e);
            }
        }
    } else {
        console.log("   No KB documents pending embedding.");
    }
    console.log("\n‚úÖ Sync Complete.");
}
await runLocalIngestion();




============================================================================================================================================================================================




This always evaluates to truthy. Consider refactoring this code.
ÓÖó
Boolean expressions should not be gratuitous typescript:S2589
Software qualities impacted:
Maintainability


2
Medium
Open
Not assigned
Code Smell
Major
Tags
cwe
...
+
Line affected
L34
Effort
10 min
Introduced
11 minutes ago
Where is the issue?
Why is this an issue?
How can I fix it?
Activity
More info

Open in IDE
scripts/run_ingestion.ts

ÓÖç
See all issues in this file


*


Show 22 more lines
New code
            headers: {
                Authorization: `Bearer ${supabaseServiceKey}`
            }
        });
        if (
error) {
            console.error("‚ùå Ingestion invocation failed with error:", error);
            if (error instanceof Error) {
                console.error("   Message:", error.message);
            }
            // Check if it's an HTTP error masked as a function error
            if (error && typeof error === 'object' && 'context' in error) {
This always evaluates to truthy. Consider refactoring this code.

                console.error("   Context:", JSON.stringify((error as any).context, null, 2));
            }
            return;
        }
        if (!data.ok) {
            console.error("‚ùå Ingestion function returned failure:", data.error);
            return;
        }


Show 17 more lines




============================================================================================================================================================================================




Remove this commented out code.
ÓÖó
Sections of code should not be commented out typescript:S125
Software qualities impacted:
Maintainability


2
Medium
Open
Not assigned
Code Smell
Major
Tags
unused
+
Line affected
L114
Effort
5 min
Introduced
11 minutes ago
Where is the issue?
Why is this an issue?
Activity

Open in IDE
supabase/functions/rag-ingest/index.ts

ÓÖç
See all issues in this file
import { createClient } from "https://esm.sh/@supabase/supabase-js@2";
import { normalizeTextForEmbedding } from '../_shared/textNormalization.ts';
const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};
interface ChunkResult {
  text: string;
  chunk_index: number;
  token_count: number;
}
// Simple sentence-aware chunking (~800 tokens target, ~120 overlap)
function chunkText(text: string, targetTokens = 800, overlapTokens = 120): ChunkResult[] {
  const sentences = text.match(/[^.!?]+[.!?]+/g) || [text];
  const chunks: ChunkResult[] = [];
  let currentChunk = '';
  let currentTokens = 0;
  let chunkIndex = 0;
  const avgCharsPerToken = 4; // rough estimate
  for (let i = 0; i < sentences.length; i++) {
    const sentence = sentences[i].trim();
    const sentenceTokens = Math.ceil(sentence.length / avgCharsPerToken);
    if (currentTokens + sentenceTokens > targetTokens && currentChunk) {
      chunks.push({
        text: currentChunk.trim(),
        chunk_index: chunkIndex++,
        token_count: currentTokens
      });
      // Start new chunk with overlap
      const overlapStart = Math.max(0, currentChunk.length - (overlapTokens * avgCharsPerToken));
      currentChunk = currentChunk.substring(overlapStart) + ' ' + sentence;
      currentTokens = Math.ceil(currentChunk.length / avgCharsPerToken);
    } else {
      currentChunk += (currentChunk ? ' ' : '') + sentence;
      currentTokens += sentenceTokens;
    }
  }
  if (currentChunk.trim()) {
    chunks.push({
      text: currentChunk.trim(),
      chunk_index: chunkIndex,
      token_count: currentTokens
    });
  }
  return chunks;
}
async function generateEmbedding(
  text: string,
  openaiKey: string,
  explicitLang?: string
): Promise<{ embedding: number[]; language: string }> {
  // Apply multilingual normalization before embedding
  const { normalized, language } = normalizeTextForEmbedding(text, explicitLang);
  console.log(`Generating embedding for language: ${language}`);
  const response = await fetch('https://api.openai.com/v1/embeddings', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${openaiKey}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      model: 'text-embedding-3-small',
      input: normalized,
      dimensions: 1536, // Explicit dimension for consistency
    }),
  });
  if (!response.ok) {
    const error = await response.text();
    throw new Error(`OpenAI API error: ${error}`);
  }
  const data = await response.json();
  return {
    embedding: data.data[0].embedding,
    language
  };
}
Deno.serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }
  try {
    // SECURITY: Only allow service_role key (NOT anon key)
    // const authHeader = req.headers.get('authorization');
    // const serviceRoleKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!;
    // if (!authHeader || !authHeader.includes(serviceRoleKey)) {
Remove this commented out code.

    //   console.error('Unauthorized ingestion attempt - service_role key required');
    //   return new Response(
    //     JSON.stringify({ 
    //       error: 'Unauthorized', 
    //       message: 'RAG ingestion requires service_role key. Never use anon key for ingestion.' 
    //     }), 
    //     { 
    //       status: 401, 
    //       headers: { ...corsHeaders, 'Content-Type': 'application/json' } 
    //     }
    //   );
    // }
    const supabaseUrl = Deno.env.get('SUPABASE_URL')!;
    const serviceRoleKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!; // Re-declare needed var
    const supabaseKey = serviceRoleKey;
    const openaiKey = Deno.env.get('OPENAI_API_KEY');
    if (!openaiKey) {
      throw new Error('OPENAI_API_KEY not configured');
    }
    const supabase = createClient(supabaseUrl, supabaseKey);
    const { source_types } = await req.json().catch(() => ({ source_types: ['transcript', 'email', 'doc', 'faq'] }));
    const results = {
      processed: 0,
      chunks_created: 0,
      embeddings_created: 0,
      by_type: {} as Record<string, number>
    };
    // Ingest transcripts
    if (source_types.includes('transcript')) {
      const { data: transcripts } = await supabase
        .from('transcripts')
        .select('id, call_sid, content, created_at, updated_at')
        .not('content', 'is', null)
        .limit(50);
      for (const transcript of transcripts || []) {
        // Detect language from content
        const { language: detectedLang } = normalizeTextForEmbedding(transcript.content);
        const sourceId = await supabase.rpc('rag_upsert_source', {
          p_source_type: 'transcript',
          p_external_id: `transcript_${transcript.id}`,
          p_title: `Call ${transcript.call_sid}`,
          p_uri: `/transcripts/${transcript.id}`,
          p_lang: detectedLang, // Use detected language
          p_meta: { call_sid: transcript.call_sid, detected_language: detectedLang }
        }).then(r => r.data);
        // Check if we need to re-embed (source was updated)
        const { data: existingChunks } = await supabase
          .from('rag_chunks')
          .select('id')
          .eq('source_id', sourceId)
          .limit(1);
        if (existingChunks && existingChunks.length > 0) {
          // Already ingested, skip
          continue;
        }
        // Chunk and embed
        const chunks = chunkText(transcript.content);
        for (const chunk of chunks) {
          const { data: chunkData } = await supabase
            .from('rag_chunks')
            .insert({
              source_id: sourceId,
              chunk_index: chunk.chunk_index,
              text: chunk.text,
              token_count: chunk.token_count,
              meta: {}
            })
            .select()
            .single();
          if (chunkData) {
            const { embedding, language: chunkLang } = await generateEmbedding(
              chunk.text,
              openaiKey,
              detectedLang
            );
            await supabase
              .from('rag_embeddings')
              .insert({
                chunk_id: chunkData.id,
                embedding: `[${embedding.join(',')}]`,
                norm: Math.sqrt(embedding.reduce((sum, val) => sum + val * val, 0)),
                meta: { language: chunkLang }
              });
            results.chunks_created++;
            results.embeddings_created++;
          }
        }
        results.processed++;
        results.by_type['transcript'] = (results.by_type['transcript'] || 0) + 1;
      }
    }
    // Ingest FAQs
    if (source_types.includes('faq')) {
      const { data: faqs } = await supabase
        .from('faqs')
        .select('id, q, a, organization_id, created_at, updated_at')
        .limit(50);
      for (const faq of faqs || []) {
        const content = `Q: ${faq.q}\n\nA: ${faq.a}`;
        // Detect language from FAQ content
        const { language: faqLang } = normalizeTextForEmbedding(content);
        const sourceId = await supabase.rpc('rag_upsert_source', {
          p_source_type: 'faq',
          p_external_id: `faq_${faq.id}`,
          p_title: faq.q,
          p_uri: `/faqs/${faq.id}`,
          p_lang: faqLang, // Use detected language
          p_meta: { org_id: faq.organization_id, detected_language: faqLang }
        }).then(r => r.data);
        const { data: existingChunks } = await supabase
          .from('rag_chunks')
          .select('id')
          .eq('source_id', sourceId)
          .limit(1);
        if (existingChunks && existingChunks.length > 0) {
          continue;
        }
        const chunks = chunkText(content);
        for (const chunk of chunks) {
          const { data: chunkData } = await supabase
            .from('rag_chunks')
            .insert({
              source_id: sourceId,
              chunk_index: chunk.chunk_index,
              text: chunk.text,
              token_count: chunk.token_count,
              meta: {}
            })
            .select()
            .single();
          if (chunkData) {
            const { embedding, language: chunkLang } = await generateEmbedding(
              chunk.text,
              openaiKey,
              faqLang
            );
            await supabase
              .from('rag_embeddings')
              .insert({
                chunk_id: chunkData.id,
                embedding: `[${embedding.join(',')}]`,
                norm: Math.sqrt(embedding.reduce((sum, val) => sum + val * val, 0)),
                meta: { language: chunkLang }
              });
            results.chunks_created++;
            results.embeddings_created++;
          }
        }
        results.processed++;
        results.by_type['faq'] = (results.by_type['faq'] || 0) + 1;
      }
    }
    return new Response(
      JSON.stringify({
        ok: true,
        results,
        timestamp: new Date().toISOString()
      }),
      { status: 200, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    );
  } catch (error) {
    console.error('RAG ingestion error:', error);
    return new Response(
      JSON.stringify({
        ok: false,
        error: error instanceof Error ? error.message : 'Ingestion failed'
      }),
      { status: 500, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    );
  }
});
