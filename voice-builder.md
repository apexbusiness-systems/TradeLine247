---
name: voice-builder
description: "Omniscient Voice AI Agent and Telephony Systems Engineer. Triggers: build voice agent, create AI phone system, voice AI architecture, telephony integration, SIP setup, WebRTC implementation, call flow design, voice API integration, fix voice latency, debug voice agent, optimize voice quality, voice AI deployment, conversational AI phone, IVR system, voice bot, phone automation, call center AI, voice assistant integration, STT/TTS setup, real-time voice, voice pipeline, telephony debugging. Produces: production-grade voice AI systems with <200ms latency, enterprise telephony architecture, optimized call flows, compliant voice solutions."
license: "Proprietary - APEX Business Systems Ltd. Edmonton, AB, Canada. https://apexbusiness-systems.com"
version: "1.0.0"
---

# Voice AI Agent & Telephony Systems Engineer

**Mission**: Build production-grade voice AI systems with <200ms latency, enterprise reliability, and human-level conversation quality.

## Quick Decision Tree

**What are you building?**
- **New voice agent** ‚Üí Section A: Architecture Selection
- **Integrating telephony** ‚Üí Section B: Telephony Stack
- **Fixing latency/quality** ‚Üí Section C: Optimization
- **Debugging issues** ‚Üí Section D: Diagnostic Tree
- **Scaling/Production** ‚Üí Section E: Production Deploy

---

## Section A: Architecture Selection

### Decision: Choose Your Stack

**Managed Platform (Fastest)?**
- **Vapi.ai** ‚Üí Best for: rapid deployment, advanced features, $0.05/min
- **Bland AI** ‚Üí Best for: outbound at scale, enterprise compliance
- **Retell AI** ‚Üí Best for: ultra-low latency, custom voices
- **Twilio Voice + AI** ‚Üí Best for: existing Twilio infrastructure

**Custom Build (Maximum Control)?**
- **WebRTC + LiveKit** ‚Üí Best for: browser-based, real-time features
- **Twilio Media Streams** ‚Üí Best for: hybrid approach, flexibility
- **FreeSWITCH/Asterisk** ‚Üí Best for: on-premise, telco-grade

**Success Criteria**:
- First response <200ms
- Turn-taking feels natural
- <3% call failure rate
- Graceful degradation on poor networks

### Pattern 1: Vapi.ai Implementation (Fastest Path)

**Input**: Use case requirements, LLM choice, voice preference  
**Output**: Production voice agent with phone number  
**Time**: 30-60 minutes

```javascript
// vapi-config.js - Production-ready template
const vapiConfig = {
  transcriber: {
    provider: "deepgram",
    model: "nova-2",
    language: "en-US",
    smartFormat: true,
    keywords: ["your_brand_name:10"] // Boost recognition
  },
  model: {
    provider: "openai",
    model: "gpt-4", // or gpt-4-turbo for speed
    temperature: 0.7,
    maxTokens: 250, // Keep responses tight
    messages: [
      {
        role: "system",
        content: `You are a professional phone assistant for [COMPANY].

CRITICAL RULES:
- Keep responses under 30 seconds
- Ask ONE question at a time
- Confirm understanding before proceeding
- Never say "I'm an AI" unless asked
- Use verbal acknowledgments: "I understand", "Got it"
- Handle interruptions gracefully

CONVERSATION STRUCTURE:
1. Greet warmly
2. Identify caller's need
3. Execute task or route appropriately
4. Confirm completion
5. Professional close

TONE: Professional, efficient, empathetic`
      }
    ]
  },
  voice: {
    provider: "11labs",
    voiceId: "21m00Tcm4TlvDq8ikWAM", // Rachel (professional)
    stability: 0.5,
    similarityBoost: 0.75,
    optimizeStreamingLatency: 4 // Max performance
  },
  firstMessage: "Hi! Thanks for calling [COMPANY]. How can I help you today?",
  
  // CRITICAL: Endpointing configuration
  endpointingConfig: {
    endpointingSensitivity: 0.5, // Lower = more patient
    clientSensitivity: 0.5,
    serverSensitivity: 0.5
  },
  
  // Call controls
  maxDurationSeconds: 900, // 15 min max
  silenceTimeoutSeconds: 30,
  
  // Recording & compliance
  recordingEnabled: true,
  hipaaEnabled: false, // Set true for healthcare
  
  // Analytics
  analysisPlan: {
    summaryPrompt: "Summarize call outcome and action items",
    structuredDataSchema: {
      outcome: "string",
      sentiment: "string",
      followUpRequired: "boolean"
    }
  }
};

// Create assistant via API
const createAssistant = async () => {
  const response = await fetch('https://api.vapi.ai/assistant', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${process.env.VAPI_API_KEY}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify(vapiConfig)
  });
  
  const assistant = await response.json();
  console.log(`‚úÖ Assistant created: ${assistant.id}`);
  return assistant;
};

// Buy phone number and link
const setupPhoneNumber = async (assistantId) => {
  // Buy number
  const numberResponse = await fetch('https://api.vapi.ai/phone-number/buy', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${process.env.VAPI_API_KEY}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      areaCode: '780', // Edmonton
      name: 'Main Line'
    })
  });
  
  const number = await numberResponse.json();
  
  // Link to assistant
  await fetch(`https://api.vapi.ai/phone-number/${number.id}`, {
    method: 'PATCH',
    headers: {
      'Authorization': `Bearer ${process.env.VAPI_API_KEY}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      assistantId: assistantId
    })
  });
  
  console.log(`‚úÖ Phone number ready: ${number.number}`);
  return number;
};
```

**Common Failures to Pre-empt**:
- ‚ùå Not setting `optimizeStreamingLatency` ‚Üí Slow responses
- ‚ùå Long system prompts (>500 words) ‚Üí Increased latency
- ‚ùå No `maxTokens` limit ‚Üí Agents ramble
- ‚ùå Missing keywords in transcriber ‚Üí Poor name recognition
- ‚ùå No endpointing tuning ‚Üí Awkward interruptions
- ‚ùå Forgetting `firstMessage` ‚Üí Dead air on pickup

### Pattern 2: Twilio Media Streams (Custom Build)

**Input**: Custom logic requirements, existing backend  
**Output**: WebSocket-based real-time voice pipeline  
**Latency**: 150-250ms achievable

```javascript
// server.js - Production Twilio + OpenAI real-time
const WebSocket = require('ws');
const express = require('express');
const OpenAI = require('openai');

const app = express();
const wss = new WebSocket.Server({ port: 8080 });

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

// State management per call
const activeCalls = new Map();

wss.on('connection', (ws) => {
  console.log('üìû New Twilio connection');
  
  let callState = {
    streamSid: null,
    audioBuffer: [],
    transcript: '',
    conversationHistory: []
  };

  ws.on('message', async (message) => {
    const msg = JSON.parse(message);
    
    switch(msg.event) {
      case 'start':
        callState.streamSid = msg.start.streamSid;
        console.log(`‚úÖ Call started: ${callState.streamSid}`);
        
        // Send greeting
        await sendTTS(ws, callState.streamSid, 
          "Hi! How can I help you today?");
        break;
        
      case 'media':
        // Accumulate audio chunks
        callState.audioBuffer.push(msg.media.payload);
        
        // Process every 1 second of audio
        if (callState.audioBuffer.length >= 50) { // ~1s at 20ms chunks
          await processAudio(ws, callState);
          callState.audioBuffer = [];
        }
        break;
        
      case 'stop':
        console.log(`üì¥ Call ended: ${callState.streamSid}`);
        activeCalls.delete(callState.streamSid);
        break;
    }
  });
});

// Process accumulated audio
async function processAudio(ws, callState) {
  // 1. Convert to audio file (use script)
  const audioData = Buffer.concat(
    callState.audioBuffer.map(b64 => Buffer.from(b64, 'base64'))
  );
  
  // 2. Transcribe with Deepgram (faster than Whisper)
  const transcript = await transcribeAudio(audioData);
  
  if (!transcript || transcript.length < 3) return; // Ignore noise
  
  console.log(`üë§ User: ${transcript}`);
  callState.conversationHistory.push({
    role: 'user',
    content: transcript
  });
  
  // 3. Get LLM response
  const response = await openai.chat.completions.create({
    model: 'gpt-4-turbo',
    messages: [
      {
        role: 'system',
        content: 'You are a helpful phone assistant. Keep responses under 30 seconds.'
      },
      ...callState.conversationHistory
    ],
    max_tokens: 150,
    temperature: 0.7
  });
  
  const aiMessage = response.choices[0].message.content;
  console.log(`ü§ñ AI: ${aiMessage}`);
  
  callState.conversationHistory.push({
    role: 'assistant',
    content: aiMessage
  });
  
  // 4. Synthesize and stream back
  await sendTTS(ws, callState.streamSid, aiMessage);
}

// TTS using ElevenLabs for quality
async function sendTTS(ws, streamSid, text) {
  const response = await fetch(
    `https://api.elevenlabs.io/v1/text-to-speech/21m00Tcm4TlvDq8ikWAM/stream`,
    {
      method: 'POST',
      headers: {
        'xi-api-key': process.env.ELEVENLABS_API_KEY,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        text: text,
        model_id: 'eleven_turbo_v2', // Fastest
        voice_settings: {
          stability: 0.5,
          similarity_boost: 0.75
        }
      })
    }
  );
  
  // Stream audio back to Twilio
  const audioStream = response.body;
  for await (const chunk of audioStream) {
    const base64Audio = chunk.toString('base64');
    ws.send(JSON.stringify({
      event: 'media',
      streamSid: streamSid,
      media: {
        payload: base64Audio
      }
    }));
  }
  
  // Send mark when done
  ws.send(JSON.stringify({
    event: 'mark',
    streamSid: streamSid,
    mark: { name: 'audio_complete' }
  }));
}

// Fast transcription with Deepgram
async function transcribeAudio(audioBuffer) {
  const response = await fetch(
    'https://api.deepgram.com/v1/listen?model=nova-2&smart_format=true',
    {
      method: 'POST',
      headers: {
        'Authorization': `Token ${process.env.DEEPGRAM_API_KEY}`,
        'Content-Type': 'audio/wav'
      },
      body: audioBuffer
    }
  );
  
  const result = await response.json();
  return result.results?.channels[0]?.alternatives[0]?.transcript || '';
}

// TwiML endpoint for inbound calls
app.post('/incoming', (req, res) => {
  res.type('text/xml');
  res.send(`
    <Response>
      <Connect>
        <Stream url="wss://your-domain.com:8080" />
      </Connect>
    </Response>
  `);
});

app.listen(3000, () => {
  console.log('‚úÖ Server running on port 3000');
});
```

**Critical Failures**:
- ‚ùå Not buffering audio correctly ‚Üí Choppy transcription
- ‚ùå No VAD (Voice Activity Detection) ‚Üí Transcribing silence
- ‚ùå Synchronous processing ‚Üí High latency
- ‚ùå Not handling Twilio marks ‚Üí Audio overlap
- ‚ùå Missing error handling on WebSocket disconnect

---

## Section B: Telephony Stack Integration

### Decision: Telephony Provider

**Need SIP trunking?** ‚Üí Twilio Elastic SIP / Telnyx  
**Need compliance?** ‚Üí Twilio Verify / Plivo (HIPAA ready)  
**Need international?** ‚Üí Vonage / Bandwidth  
**Need cost optimization?** ‚Üí Telnyx / SignalWire  

### SIP Configuration (Production Template)

```bash
# FreeSWITCH dialplan.xml - Production grade
<extension name="inbound_ai_agent">
  <condition field="destination_number" expression="^(\+1780\d{7})$">
    <!-- Log call -->
    <action application="log" data="INFO Incoming call from ${caller_id_number}"/>
    
    <!-- Answer immediately -->
    <action application="answer"/>
    
    <!-- Set codecs for quality -->
    <action application="set" data="absolute_codec_string=OPUS,PCMU,PCMA"/>
    
    <!-- Enable recording -->
    <action application="set" data="RECORD_TITLE=${uuid}"/>
    <action application="set" data="RECORD_COPYRIGHT=APEX Business Systems"/>
    <action application="record_session" data="/var/recordings/${uuid}.wav"/>
    
    <!-- Connect to AI agent via WebSocket -->
    <action application="socket" data="localhost:8080 async full"/>
    
    <!-- Fallback on error -->
    <action application="playback" data="/sounds/technical_difficulty.wav"/>
    <action application="hangup"/>
  </condition>
</extension>
```

**Common SIP Failures**:
- ‚ùå Wrong codec negotiation ‚Üí Audio quality issues
- ‚ùå No DTMF relay setup ‚Üí IVR buttons don't work
- ‚ùå Missing RTP timeout ‚Üí Calls don't drop on silence
- ‚ùå No NAT traversal config ‚Üí One-way audio
- ‚ùå Improper INVITE handling ‚Üí Calls fail randomly

---

## Section C: Optimization (Latency & Quality)

### Latency Budget Breakdown

**Target**: <200ms total response time

| Component | Budget | Optimization |
|-----------|--------|--------------|
| **STT** | 50-80ms | Use Deepgram Nova-2 or AssemblyAI |
| **LLM** | 80-120ms | Use GPT-4 Turbo or Claude 3.5 Haiku |
| **TTS** | 50-70ms | Use ElevenLabs Turbo or Play.ht |
| **Network** | <30ms | Use edge deployment, CDN |

### Latency Optimization Checklist

```javascript
// optimize-latency.js - Apply all these patterns

// 1. STREAMING: Never wait for complete responses
const streamResponse = async (prompt) => {
  const stream = await openai.chat.completions.create({
    model: 'gpt-4-turbo',
    messages: [{ role: 'user', content: prompt }],
    stream: true, // CRITICAL
    max_tokens: 150 // Limit for speed
  });
  
  let buffer = '';
  for await (const chunk of stream) {
    const content = chunk.choices[0]?.delta?.content || '';
    buffer += content;
    
    // Stream to TTS immediately on sentence boundary
    if (content.match(/[.!?]/)) {
      await streamTTS(buffer);
      buffer = '';
    }
  }
};

// 2. PARALLEL PROCESSING: Don't chain sequentially
const parallelProcess = async (audio) => {
  const [transcript, sentiment, intent] = await Promise.all([
    transcribe(audio),
    analyzeSentiment(audio),
    detectIntent(audio)
  ]);
  // Use all results together
};

// 3. EDGE CACHING: Cache common responses
const cache = new Map();
const getCachedResponse = async (key) => {
  if (cache.has(key)) {
    return cache.get(key); // Instant response
  }
  const response = await generateResponse(key);
  cache.set(key, response);
  return response;
};

// 4. PREFETCH: Start TTS before LLM finishes
let ttsQueue = [];
const prefetchTTS = async (partialText) => {
  // Start generating audio for likely responses
  if (partialText.length > 20) {
    ttsQueue.push(synthesize(partialText));
  }
};

// 5. CONNECTION POOLING: Reuse connections
const agent = new https.Agent({
  keepAlive: true,
  maxSockets: 50
});

// 6. COMPRESSION: Enable audio compression
const compressAudio = (pcmData) => {
  return opus.encode(pcmData, {
    rate: 16000,
    bitrate: 24000 // Balance quality vs size
  });
};
```

**Quality Optimization**:

```javascript
// Audio quality configuration
const qualityConfig = {
  // Noise suppression
  noiseSuppression: {
    enabled: true,
    level: 'high',
    type: 'krisp' // Best-in-class
  },
  
  // Echo cancellation
  echoCancellation: {
    enabled: true,
    tailLength: 256 // ms
  },
  
  // Automatic Gain Control
  agc: {
    enabled: true,
    targetLevel: -18 // dBFS
  },
  
  // Jitter buffer for packet loss
  jitterBuffer: {
    minDelay: 20,
    maxDelay: 200,
    adaptive: true
  }
};
```

---

## Section D: Debugging Decision Tree

**Issue: High Latency**
1. Measure each component ‚Üí Use script `diagnose-latency.py`
2. STT slow? ‚Üí Switch provider or upgrade tier
3. LLM slow? ‚Üí Reduce max_tokens, use faster model
4. TTS slow? ‚Üí Enable streaming, use Turbo models
5. Network? ‚Üí Check edge deployment, use CDN

**Issue: Poor Audio Quality**
1. One-way audio? ‚Üí NAT/firewall, check RTP
2. Choppy/robotic? ‚Üí Codec mismatch, increase bitrate
3. Echo? ‚Üí Enable AEC, check speaker/mic isolation
4. Noise? ‚Üí Enable Krisp, upgrade noise suppression

**Issue: Conversation Problems**
1. Interrupts poorly? ‚Üí Tune endpointing sensitivity
2. Talks over user? ‚Üí Implement better VAD
3. Rambles? ‚Üí Reduce max_tokens, add "be brief" to prompt
4. Misunderstands? ‚Üí Add keywords, improve prompt, use examples

**Issue: Call Failures**
1. Check SIP response codes ‚Üí Use script `analyze-sip-logs.py`
2. 503 Service Unavailable ‚Üí Provider outage, add failover
3. 408 Request Timeout ‚Üí Network issue, increase timeout
4. 488 Not Acceptable ‚Üí Codec negotiation, fix SDP

---

## Section E: Production Deployment

### Pre-Flight Checklist

```yaml
# production-checklist.yml
infrastructure:
  - [ ] Load balancer configured with health checks
  - [ ] Auto-scaling enabled (CPU >70%)
  - [ ] CDN for static assets
  - [ ] Database connection pooling
  - [ ] Redis for session management

monitoring:
  - [ ] Call quality metrics (MOS scores)
  - [ ] Latency tracking (<200ms p95)
  - [ ] Error rate alerts (<1%)
  - [ ] Uptime monitoring (99.9%+ SLA)
  - [ ] Cost tracking per minute

security:
  - [ ] HTTPS/WSS only
  - [ ] API key rotation
  - [ ] Rate limiting (100 req/min per IP)
  - [ ] Input sanitization
  - [ ] PCI compliance (if payments)
  - [ ] HIPAA compliance (if healthcare)

compliance:
  - [ ] Call recording consent
  - [ ] TCPA compliance (opt-in required)
  - [ ] GDPR data retention policies
  - [ ] Accessibility (WCAG 2.1 AA)
  - [ ] E911 registration (if PSTN)

testing:
  - [ ] Load test (1000 concurrent calls)
  - [ ] Failover testing
  - [ ] Poor network simulation
  - [ ] Multi-language testing
  - [ ] Edge case scenarios
```

### Production Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Phone/SIP     ‚îÇ
‚îÇ   Provider      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Load Balancer  ‚îÇ  ‚Üê Cloudflare/AWS ALB
‚îÇ  + Rate Limit   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚ñº         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Node  ‚îÇ ‚îÇ Node  ‚îÇ  ‚Üê Auto-scaling group
‚îÇ   1   ‚îÇ ‚îÇ   2   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ         ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  WebSocket      ‚îÇ
‚îÇ  Manager        ‚îÇ  ‚Üê Persistent connections
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚ñº                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   STT   ‚îÇ    ‚îÇ   LLM    ‚îÇ  ‚Üê Parallel processing
‚îÇ Service ‚îÇ    ‚îÇ Service  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ               ‚îÇ
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚ñº
      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
      ‚îÇ    TTS     ‚îÇ
      ‚îÇ  Service   ‚îÇ
      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚ñº
      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
      ‚îÇ   Redis    ‚îÇ  ‚Üê Session state
      ‚îÇ   Cache    ‚îÇ
      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Critical Anti-Patterns (NEVER DO)

‚ùå **Blocking I/O** ‚Üí Always async/await  
‚ùå **No timeout handling** ‚Üí Calls hang forever  
‚ùå **Hardcoded credentials** ‚Üí Use env vars  
‚ùå **No fallback strategy** ‚Üí Single point of failure  
‚ùå **Ignoring DTMF** ‚Üí Users can't navigate IVR  
‚ùå **No call recording consent** ‚Üí Legal liability  
‚ùå **Long prompts** ‚Üí Increases latency  
‚ùå **No conversation memory** ‚Üí Repetitive questions  
‚ùå **Synchronous LLM calls** ‚Üí Terrible UX  
‚ùå **No monitoring** ‚Üí Flying blind in production  

---

## Advanced Patterns

### Pattern: Interruption Handling

```javascript
// Advanced interruption detection
class InterruptionHandler {
  constructor() {
    this.isSpeaking = false;
    this.audioQueue = [];
  }
  
  async handleUserSpeech(transcript) {
    if (this.isSpeaking) {
      // User interrupted - stop immediately
      this.stopCurrentAudio();
      this.audioQueue = []; // Clear queue
      console.log('üõë User interrupted');
    }
    
    // Process new input
    await this.processUserInput(transcript);
  }
  
  async playAudio(audioData) {
    this.isSpeaking = true;
    try {
      await this.streamAudio(audioData);
    } finally {
      this.isSpeaking = false;
    }
  }
  
  stopCurrentAudio() {
    // Send stop signal to audio stream
    this.emit('stop-audio');
    this.isSpeaking = false;
  }
}
```

### Pattern: Multi-Language Support

```javascript
// Automatic language detection and switching
const detectAndSwitch = async (audio) => {
  const detected = await detectLanguage(audio);
  
  return {
    transcriber: {
      language: detected.code,
      model: detected.code === 'en' ? 'nova-2' : 'whisper-large'
    },
    voice: {
      voiceId: VOICE_MAP[detected.code], // Pre-configured voices
      model: 'eleven_multilingual_v2'
    },
    prompt: PROMPTS[detected.code] // Localized system prompt
  };
};
```

---

## Reference Documents

Complex topics moved to `/references/`:
- `telephony-protocols.md` - Deep dive on SIP, RTP, WebRTC
- `voice-quality-metrics.md` - MOS scoring, audio analysis
- `compliance-guide.md` - TCPA, GDPR, HIPAA requirements
- `provider-comparison.md` - Feature matrix of all platforms
- `latency-optimization.md` - Advanced performance techniques
- `testing-scenarios.md` - Edge cases and load testing

## Scripts

- `scripts/diagnose-latency.py` - Component-level latency analysis
- `scripts/analyze-sip-logs.py` - SIP troubleshooting automation
- `scripts/load-test.py` - Stress test voice infrastructure
- `scripts/quality-check.py` - Audio quality validation

---

**Version**: 1.0.0  
**Updated**: January 2025  
**License**: APEX Business Systems Ltd.
